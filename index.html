<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>DreamMover: Leveraging the Prior of Diffusion Models for Image Interpolation with Large Motion</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h1 class="title is-1 publication-title"><font color=DeepSkyBlue>DreamM<span style='font-size:30px;'>&#128060;</span>ver:</font> Leveraging the Prior of Diffusion Models <br> for Image Interpolation with Large Motion</h1>
            <!-- <h1>:Leveraging the Prior of Diffusion Models</h1> -->
            <!-- <h1> for Image Interpolation with Large Motion</h1> -->
            <h4 style="color:#5a6268;">ECCV,2024</h4>
            <hr>
            <h6><a href="https://leoshen917.github.io/" target="_blank">Liao Shen</a><sup>1</sup>, 
                <a href="https://tqtqliu.github.io/" target="_blank">Tianqi Liu</a><sup>1</sup>, 
                <a href="https://huiqiang-sun.github.io/" target="_blank">Huiqiang Sun</a><sup>1</sup>, 
                <a href="https://scholar.google.com/citations?user=g_Y0w7MAAAAJ&hl" target="_blank">Xinyi Ye</a><sup>1</sup>, 
                <a href="https://dblp.org/pid/44/3801.html" target="_blank">Baopu Li</a><sup>1</sup>, 
                <a href="https://jimmie33.github.io/" target="_blank">Jianming Zhang</a><sup>2</sup>,
                <a href="http://english.aia.hust.edu.cn/info/1030/1072.htm" target="_blank">Zhiguo Cao</a><sup>1*</sup>,
            </h6>
            <p><sup>1</sup>Huazhong University of Science and Technology &nbsp;&nbsp; 
               <sup>2</sup>Adobe Research</p>
            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/leoShen917/DreamMover/blob/main/pdf/paper.pdf" role="button"  target="_blank"> <!-- 需要改 -->
                    <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2409.09605" role="button"  target="_blank"> <!-- 需要改 -->
                    <i class="fa fa-file"></i> arXiv </a> </p>
              </div>
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://youtu.be/sqCy7ffTEEY" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Video </a> </p>
              </div> -->
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/leoShen917/DreamMover" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/xingyi-li/3d-cinemagraphy/blob/main/pdf/3d-cinemagraphy-supp.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Supplementary </a> </p>
              </div> -->
              <!-- <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/xingyi-li/3d-cinemagraphy/blob/main/pdf/3d-cinemagraphy-poster.pdf" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Poster </a> </p> -->
            </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
<!--             <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/teaser_no_audio.mp4" type="video/mp4">
              </video> -->
            <img class="img-fluid" src="images/teaser1.png">
              <!-- <br><br> -->
          <p class="text-justify">  </p>
          <p class="text-justify">Given two input images with large motion, our proposed method can generate a short video with high fidelity and semantic consistency compared to previous approaches.
</p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/teaser.mp4" type="video/mp4">
              </video>
<!--             <img class="img-fluid" src="images/pipeline-v4.png"> -->
              <!-- <br><br> -->
          <p class="text-justify">  </p>
          <p class="text-justify">We study the problem of generating intermediate images from image pairs with large motion while maintaining semantic consistency. Due to the large motion, the intermediate semantic information may be absent in input images. Existing methods either limit to small motion or focus on topologically similar objects, leading to artifacts and inconsistency in the interpolation results. To overcome this challenge, we dig into the pre-trained image diffusion models for their capabilities in semantic representations and generations, which ensures consistent expression of the absent intermediate semantic representations with the input. To this end, we propose DreamMover, a novel image interpolation framework with three main components: 1) A natural flow estimator based on the diffusion model that can implicitly reason about the semantic correspondence between two images. 2) To avoid loss of detailed information during fusion, our key insight is to fuse information in two parts, high-level space and low-level space. 3) To enhance the consistency between the generated images and input, we propose the self-attention concatenation and replacement approach. Lastly, we present a challenging benchmark dataset called InterpBench to evaluate the semantic consistency of generated results. Extensive experiments demonstrate the effectiveness of our method. Code will be released soon.</p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Overview video</h3>
            <hr style="margin-top:0px">
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/sqCy7ffTEEY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br> -->

   <!-- method -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Method</h3>
            <hr style="margin-top:0px">
<!--             <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/teaser_no_audio.mp4" type="video/mp4">
              </video> -->
            <img class="img-fluid" src="images/pipeline.png">
              <!-- <br><br> -->
          <p class="text-justify">  </p>
          <p class="text-justify">Given two input images, each is fed into the pre-trained diffusion model for adding noise via DDIM inversion. We extract feature maps from up-blocks of U-Net, and leverage them to get the pixel correspondences of the two images to yield the bidirectional optical flow. We decompose the noisy latent code into low-level and high-level components. To maintain the high-frequency information of images, we perform softmax splatting and time interpolation on high-level space. As for low-level space, we replace all weighted average operations with "Winner-Takes-All"(WTA). In addition, we propose a novel self-attention concatenation and replacement method for consistency. Finally, our method can generate a sequence of high fidelity and consistency interpolation frames.
</p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Results</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/results1.mp4" type="video/mp4">
              </video>
              <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/results2.mp4" type="video/mp4">
            </video>
<!--             <img class="img-fluid" src="images/pipeline-v4.png"> -->
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Dynamic Comparison</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/comparison1.mp4" type="video/mp4">
              </video>
              <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/comparison2.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="images/comparison3.mp4" type="video/mp4">
          </video>
          <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
            <source src="images/comparison4.mp4" type="video/mp4">
        </video>
<!--             <img class="img-fluid" src="images/pipeline-v4.png"> -->
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
<!--             <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/teaser_no_audio.mp4" type="video/mp4">
              </video> -->
              <h3>Visualization Comparison</h3>
            <hr style="margin-top:0px">
            <img class="img-fluid" src="images/visualisation.png">
              <!-- <br><br> -->
          <p class="text-justify">  </p>
          <p class="text-justify">More Visualization Comparison of baselines and our method. We show the middle-most image obtained by all methods. Our approach generates intermediate results that maintain the best semantic consistency.</p>
        </div>
      </div>
    </div>
  </section>
  <br>
  <!-- Appearsnce Hallucination
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3> Appearance Hallucination of Brandenburg Gate </h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/app_Gate_c.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> of Brandenburg Gate -->

  <!-- Appearance
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Appearance Hallucination of Brandenburg Gate</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/app_Gate_c.mp4" type="video/mp4">
            <h3>Appearance Hallucination of Trevi Fountain</h3>
            <hr style="margin-top:0px">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/app_Fountain_c.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> Hallucination -->

 <!-- Appearance Hallucination -->
<!--   <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Appearance Hallucination</h3>
            <hr style="margin-top:0px">
            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Brandenburg Gate</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/app_Gate_c.mp4" type="video/mp4">
            </video>

            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Trevi Fountain</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/app_Fountain_c.mp4" type="video/mp4">
            </video>
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- Cross-Appearance Hallucination -->
<!--   <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Cross-Appearance Hallucination</h3>
            <hr style="margin-top:0px">
            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">From Trevi Fountain to Brandenburg Gate</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/Fountain2Gate_c.mp4" type="video/mp4">
            </video>

            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">From Brandenburg Gate to Trevi Fountain</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/Gate2Fountain_c.mp4" type="video/mp4">
            </video>
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- Appearance Hallucination From Artworks -->
<!--   <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Appearance Hallucination From Artworks</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/art_c.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

<!-- citing -->
<div class="container">
  <div class="row ">
    <div class="col-12">
        <h3>Citation</h3>
        <hr style="margin-top:0px">
            <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{shen2024dreammover,
  title={DreamMover: Leveraging the Prior of Diffusion Models for Image Interpolation with Large Motion},
  author={Shen, Liao and Liu, Tianqi and Sun, Huiqiang and Ye, Xinyi and Li, Baopu and Zhang, Jianming and Cao, Zhiguo},
  journal={arXiv preprint arXiv:2409.09605},
  year={2024}
}
</code></pre>
        <hr>
    </div>
  </div>
</div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>
  <div class="section" style="text-align:center; padding:0 0 20px 0">
    <a href="https://clustrmaps.com/site/1c0az"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=nZv9K4lgbT_6bqyhcybzgXaeoDl_UU0mzFefY0U6bEY&cl=ffffff" /></a>
</div>

</body>
</html>
